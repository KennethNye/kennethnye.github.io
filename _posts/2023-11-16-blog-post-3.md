---
layout: single
title:  "Stochastic Process (aka Random Process)"
date : 2023-11-16
header:
  teaser: "unsplash-gallery-image-2-th.jpg"
permalink: /posts/2023/11/blog-post-3/
tags:
  - Research
render_with_liquid: false
---

## Definition of Stochastic Process

Given a probability space $(\Omega,\mathcal{F},\mathbb{P})$, the index set $I=\mathbb{N,R,R _ {\ge0}},\Theta$ and a measurable space $(\mathbb{S},\mathcal{S})$ (aka the state space), a stochastic process is defined as

$$
X(i,\omega):I\times\Omega\to\mathbb{S}
$$

Often, we write $X(i,\omega)$ as $\{X _ i\} _ {i\in I}$.

- With a fixed $i\in I$, $X(i,\cdot)$ is a random variable

    $$
    X(i,\cdot):(\Omega,\mathcal{F})\to(\mathbb{S},\mathcal{S})
    $$

    Often, we write $X(i,\cdot)$ as $X _ i(\omega)$
- With a fixed $\omega\in \Omega$, $X(\cdot,\omega)$ is a function, which is called a sample path or realization

    $$
    X(\cdot,\omega):I\to\mathbb{S}
    $$

    Often, we write $X(\cdot,\omega)$ as $\{X _ i(\omega)\} _ {i\in I}$

### Stochastic processes indexed by $\mathbb{N}$

- Bernoulli process

   The sample space $\Omega$ consists of all possible outcomes of tossing a coin infinitely many times. An example of an element in the sample space $\Omega$ is

   $$
   \omega=HHH\cdots
   $$

   The state space is $\mathbb{S}=\{0,1\}$ where $0$ represents a tail while $1$ represents a haed.
   The index set is $\mathbb{N}=\{1,2,\cdots\}$, which is used to indicate the number of tosses. The stochastic process is defined as

   $$
   X(n,\omega)=\left\{{\begin{matrix}&1, &n\textrm{-th toss is head}\\&0, &n\textrm{-th toss is tail}\end{matrix}}\right.
   $$

- Random walk

   Let's take the sample space above and use the same index set. Instead, we define

   $$
   X(n,\omega)=\textrm{number of heads in }\omega - \textrm{number of tails in }\omega \textrm{ in the first }n \textrm{ tosses}
   $$

   The state space will be $\mathbb{Z}$

### Stochastic processes indexed by $\mathbb{R,R _ {\ge0}}$

- Gaussian process

   Gaussian process is a stochastic process such that for any finite subset $I\subset \mathbb{I}$, the collection of random variables $\{X _ i\} _ {i\in I}$ have a (multivariate) normal distribution, which is equivalent to that every finite linear combination of them is normally distributed.
- [Wiener Process (aka, Brownian motion)](https://people.math.wisc.edu/~roch/grad-prob/gradprob-notes26.pdf)

   Note that Wiener process is particular case of Gaussian Process. The continuous-time stochastic process $X:=\{X _ t\} _ {t\in R _ {\ge0}}$ is a standard Brownian motion if it is a Gaussian process with almost surely continuous paths, that is,

   $$
   \mathbb{P}\left\{\omega\in\Omega:\{X _ t(\omega)\} _ {t\in R _ {\ge0}} \textrm{ is continuous in }t\right\} = 1
   $$

   such that $X _ 0 = 0$, $\mathbb{E}[X _ t] = 0$, and $\mathrm{Cov}[X _ s, X _ t] = s \wedge t$. More generally, $B = \sigma X + x$ is a Brownian motion started at $x$.

### Counting Processes

- Poisson point process

    Counting process $\{N _ t\} _ {t\in\mathbb{R _ {\ge0}}}$ counts the number of arrivals up to time $t$. A counting process is a homogeneous Poisson process with rate $\lambda>0$ if it has the following three properties:

  - $N _ 0=0$
  - has independent increment and
  - the number of events (or points) in any interval of length $t$ is a Poisson Random variable with mean $\lambda t$.

### Stochastic processes indexed by a parameter space $\Theta$

- Dirichlet Process

    Dirichlet Process $\mathrm{DP}(\alpha,H)$ with a scaling parameter $\alpha$ and a base probability distribution $H$ on support $\Theta$ is a distribution over probability distributions. The support $\Theta$ here serves as the index set.
    The sample path or a realization of a DP is an atomic probability measure $f(\theta)$ over $\theta\in \Theta$. DP is such that for any measurable finite partition of $\Theta$, $\{B _ i\} _ {i=1}^n$

    If $X\sim \mathrm{DP}(\alpha,H)$, then $\left(X(B _ 1),X(B _ 2),\cdots,X(B _ n)\right)\sim\mathrm{Dir}\left(\alpha H(B _ 1), \alpha H(B _ 2),\cdots, \alpha H(B _ n)\right)$

## Definition of Random measure

Random measure are different from random process where the former is defined on the $\sigma$-algebra of the metric space $S$ while the latter is defined on an index set $I$. Intuitive, you can treat random measure as a stochastic process indexed by the set from the $\sigma$-algebra.

- Point Process

    To define general point processes, we start with a probability space $(\Omega, \mathcal{F}, P)$, and a measurable space $(S, \mathcal{S})$ where $S$ is a locally compact space|locally compact second-countable space|second countable Hausdorff space and $\mathcal{S}$ is its Borel sigma-algebra. Consider now an integer-valued locally finite kernel $\xi$ from $(\Omega, \mathcal{F})$ into $(S, \mathcal{S})$, that is, a mapping $\Omega \times \mathcal{S} \mapsto \mathbb{Z} _ {+}$ such that:
  - For every $\omega \in \Omega$, $\xi(\omega, \cdot)$ is a locally finite measure on $S$. The values that this mapping taking are integers rather then real numbers, so this can not be considered as a measure.
  - For every $B \in \mathcal{S}$, $\xi(\cdot, B): \Omega \mapsto \mathbb{Z} _ +$ is a random variable over $\mathbb{Z} _ +$.
